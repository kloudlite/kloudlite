apiVersion: plugin-helm-chart.kloudlite.github.com/v1
kind: HelmPipeline
metadata:
  name: kloudlite-platform
  namespace: kloudlite
spec:
  jobVars:
    tolerations:
      - operator: Exists

  pipeline:
    # aws ebs csi driver
    - release:
        name: aws-ebs-csi
        namespace: kloudlite
      chart:
        url: https://kubernetes-sigs.github.io/aws-ebs-csi-driver
        name: aws-ebs-csi-driver
        version: 2.22.0

      helmValues:
        controller:
          nodeSelector: {{.csi.nodeSelector | toJson}}
          tolerations: {{.csi.tolerations | toJson}}

        node:
          nodeSelector: {{.csi.nodeSelector | toJson}}
          tolerations: {{.csi.tolerations | toJson}}

        storageClasses: 
          - name: {{.csi.storage_classes.xfs}}
            volumeBindingMode: "WaitForFirstConsumer"
            reclaimPolicy: "Retain"
            parameters:
              encrypted: "false"
              type: {{.csi.storage_type}}
              fsType: "xfs"

          - name: {{.csi.storage_classes.ext4}}
            volumeBindingMode: "WaitForFirstConsumer"
            reclaimPolicy: "Retain"
            parameters:
              encrypted: "false"
              type: {{.csi.storage_type}}
              fsType: "ext4"

      preInstall: |+ #bash
        # volume snapshot classes
        kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/client/config/crd/snapshot.storage.k8s.io_volumesnapshotclasses.yaml

        # volume snapshot contents
        kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/client/config/crd/snapshot.storage.k8s.io_volumesnapshotcontents.yaml

        # volume snapshots
        kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/client/config/crd/snapshot.storage.k8s.io_volumesnapshots.yaml

        # installing volume snapshot controller RBACs
        kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/deploy/kubernetes/snapshot-controller/rbac-snapshot-controller.yaml

        # installing volume snapshot controller deployment
        kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/deploy/kubernetes/snapshot-controller/setup-snapshot-controller.yaml

      postInstall: |+ #bash
        echo "making sure sc-ext4 is the default storage class"

        kubectl get sc/local-path -o=jsonpath={.metadata.name}
        exit_code=$?

        if [ $exit_code -eq 0 ]; then
          kubectl patch storageclass local-path -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"false"}}}'
        fi

        kubectl get sc/{{.csi.storage_classes.ext4}} -o=jsonpath={.metadata.name}
        exit_code=$?
        if [ $exit_code -eq 0 ]; then
          kubectl patch storageclass {{.csi.storage_classes.ext4}} -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
        fi

    - release:
        name: cert-manager
        namespace: kloudlite
      chart:
        url: https://charts.jetstack.io
        name: cert-manager
        version: "v1.17.2"

      preInstall: |+ #bash
        echo "installing cert-manager CRDs"
        kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.17.2/cert-manager.crds.yaml
        echo "installed cert-manager CRDs"

      postInstall: |+ #bash
        cat <<EOF | kubectl apply -f -
        apiVersion: cert-manager.io/v1
        kind: ClusterIssuer
        metadata:
          name: {{.cert_manager.cluster_issuer.name}}
        spec:
          acme:
            email: {{.cert_manager.cluster_issuer.acme.email}}
            privateKeySecretRef:
              name: {{.cert_manager.cluster_issuer.name}}
            server: {{.cert_manager.cluster_issuer.acme.server | default "https://acme-v02.api.letsencrypt.org/directory" }}
            solvers:
              - dns01:
                  route53: {}
                selector:
                  dnsNames:
                    - "{{.cert_manager.wildcard_cert.host}}"
                    - "*.{{.cert_manager.wildcard_cert.host}}"

              {{- if .ingress_nginx.ingress_class }}
              - http01:
                  ingress:
                    class: {{.ingress_nginx.ingress_class | squote}}
              {{- end }}
        EOF

        {{- if .cert_manager.wildcard_cert.host }}
        cat <<EOF | kubectl apply -f -
        apiVersion: cert-manager.io/v1
        kind: Certificate
        metadata:
          name: {{.cert_manager.wildcard_cert.secret_name}}
          namespace: {{.release.namespace}}
        spec:
          secretName: {{.cert_manager.wildcard_cert.secret_name}}
          issuerRef:
            name: {{.cert_manager.cluster_issuer.name}}
            kind: ClusterIssuer
          commonName: "*.{{.cert_manager.wildcard_cert.host}}"
          dnsNames:
          - "*.{{.cert_manager.wildcard_cert.host}}"
        EOF
        {{- end }}

      helmValues:
        # -- cert-manager args, forcing recursive nameservers used to be google and cloudflare
        # @ignored
        extraArgs:
          - "--dns01-recursive-nameservers-only"
          - "--dns01-recursive-nameservers=1.1.1.1:53,8.8.8.8:53"

        nodeSelector: {{ .cert_manager.nodeSelector | toJson }}
        tolerations: {{ .cert_manager.tolerations | toJson }}

        startupapicheck:
          enabled: false

        resources:
          limits:
            cpu: 80m
            memory: 120Mi
          requests:
            cpu: 40m
            memory: 120Mi

        webhook:
          nodeSelector: {{ .cert_manager.nodeSelector | toJson }}
          tolerations: {{ .cert_manager.tolerations | toJson }}

          resources:
            limits:
              cpu: 60m
              memory: 60Mi
            requests:
              cpu: 30m
              memory: 60Mi

        cainjector:
          nodeSelector: {{ .cert_manager.nodeSelector | toJson }}
          tolerations: {{ .cert_manager.tolerations | toJson }}

          resources:
            limits:
              cpu: 120m
              memory: 200Mi
            requests:
              cpu: 80m
              memory: 200Mi

    - release:
        name: ingress-nginx
        namespace: kloudlite
      chart:
        url: https://kubernetes.github.io/ingress-nginx
        name: ingress-nginx
        version: v4.12.0

      helmValues:
        nameOverride: ingress-nginx

        rbac:
          create: true

        serviceAccount:
          create: true
          name: ingress-nginx-sa

        controller:
          # -- ingress nginx controller configuration
          kind: Deployment
          service:
            type: LoadBalancer

          watchIngressWithoutClass: false
          ingressClassByName: true
          ingressClass: &class {{.ingress_nginx.ingress_class}}
          electionID: {{.ingress_nginx.ingress_class}}
          ingressClassResource:
            enabled: true
            name: {{.ingress_nginx.ingress_class}}
            controllerValue: "k8s.io/{{ .ingress_nginx.ingress_class}}"

          {{ if .cert_manager.wildcard_cert.host }}
          extraArgs:
            default-ssl-certificate: "{{.release.namespace}}/{{.cert_manager.wildcard_cert.secret_name}}"
          {{ end }}

          resources:
            requests:
              cpu: 100m
              memory: 200Mi

          admissionWebhooks:
            enabled: true
            failurePolicy: Ignore

    - release:
        name: nats
        namespace: kloudlite
      chart:
        url: https://nats-io.github.io/k8s/helm/charts/
        name: nats
        version: 1.3.6

      postInstall: |+ #bash
        cat <<'EOF' | kubectl apply -f -
        apiVersion: batch/v1
        kind: Job
        metadata:
          name: nats-setup-job-{{ randAlphaNum 5 | lower }}
          namespace: {{ .release.namespace }}
        spec:
          template:
            spec:
              tolerations: {{ .nats.tolerations | toJson }}
              nodeSelector: {{ .nats.nodeSelector | toJson }}
              containers:
              - name: nats-manager
                {{- /* image: natsio/nats-box:0.14.1 */}}
                image: ghcr.io/kloudlite/hub/nats:latest
                command: ["bash"]
                args:
                - -c
                - |+
                  echo "creatings NATS KVs"
                  {{- range $k, $bucket := .nats.buckets }}
                  nats --server "nats://nats:4222" kv add {{ $bucket.name }} --storage={{$bucket.storage}}
                  {{- end }}

                  echo "creatings NATS STREAMs"
                  {{- range $k, $stream := .nats.streams }}
                  params=(
                    --server "nats://nats:4222"
                    --replicas=1
                    --subjects={{ $stream.subject | squote }}
                    --max-msg-size={{ $stream.max_msg_bytes }}
                    {{ if $stream.max_msgs_per_subject }}--max-msgs-per-subject={{$stream.max_msgs_per_subject}}{{end}}
                    {{- /* {{ if $stream.max_age }}--max-age={{$stream.max_age}}{{ end }} */}}
                    {{ if $stream.work_queue }}--retention="work"{{ end }}
                    --storage=file
                    --compression=s2
                    --discard=old
                    --defaults
                  )
                  nats stream add "${params[@]}" "{{$stream.name}}"
                  {{- end }}
              restartPolicy: Never
          backoffLimit: 0
        EOF

      helmValues:
        fullnameOverride: nats
        namespaceOverride: {{.release.namespace}}

        config:
          jetstream:
            enabled: true
            fileStore:
              enabled: true
              dir: /data
              pvc:
                enabled: true
                size: {{.nats.storage}}
                storageClassName: {{.csi.storage_classes.xfs}}
                name: "{{.release.name}}-jetstream-pvc"

        natsBox:
          enabled: true
          podTemplate:
            merge:
              spec:
                tolerations: {{.nats.tolerations | toJson }}
                nodeSelector: {{.nats.nodeSelector | toJson }}

        podTemplate:
          merge:
            spec:
              tolerations: {{ .nats.tolerations | toJson }}
              nodeSelector: {{ .nats.nodeSelector | toJson }}

    - release:
        name: mongodb
        namespace: kloudlite
      chart:
        url: https://kloudlite.github.io/helm-charts-extras
        name: mongodb
        version: v1.0.0
      helmValues: {}

    - release:
        name: kloudlite-platform-operator
        namespace: kloudlite
      chart:
        url: https://kloudlite.github.io/helm-charts
        name: kloudlite-platform-operator
        version: "{{.kloudlite_release}}"

      preInstall: |+ #bash
        kubectl apply -f https://github.com/kloudlite/helm-charts/releases/download/{{.kloudlite_release}}/crds-all.yml --server-side
        kubectl apply -f https://raw.githubusercontent.com/kloudlite/plugin-k3s-cluster/refs/heads/master/config/crd/bases/plugin-k3s-cluster.kloudlite.github.com_k3sclusters.yaml --server-side

      helmValues:
        clusterInternalDNS: "cluster.local"

        image:
          name: ghcr.io/kloudlite/kloudlite/operator/platform
          tag: ""

        helmJobRunnerImage:
          name: "ghcr.io/kloudlite/plugin-helm-chart/helm-job-runner"
          tag: "v1.0.0"


        certManager:
          clusterIssuer: "{{.cert_manager.cluster_issuer.name }}"

        ingress:
          ingressClass: {{.ingress_nginx.ingress_class}}


    - release:
        name: kloudlite-platform
        namespace: kloudlite
      chart:
        url: https://kloudlite.github.io/helm-charts
        name: kloudlite-platform-mini
        version: "{{.kloudlite_release}}"

      helmValues:
        kloudliteRelease: "{{.kloudlite_release}}"
        baseDomain: "{{.web_host}}"
        clusterInternalDNS: "cluster.local"

        mongo:
          secretKeyRef:
            name: "mongodb-creds"
            key: "MONGODB_URI"

        nats:
          url: "nats://nats:4222"

        ingress:
          ingressClass: {{.ingress_nginx.ingress_class}}

        certManager:
          clusterIssuer:
            name: {{.cert_manager.cluster_issuer.name }}
